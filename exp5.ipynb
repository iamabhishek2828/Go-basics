{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "383ef24a",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 30px; font-weight: bold; margin-bottom: 20px;\">\n",
    "    Program 5\n",
    "</div>\n",
    "\n",
    "\n",
    "### **Aim**\n",
    "Transfer Learning on pretrained model (ResNet, VGG-16) for MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3643ad04",
   "metadata": {},
   "source": [
    "### **Theory**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af195832",
   "metadata": {},
   "source": [
    "#### Transfer Learning\n",
    "\n",
    "Transfer learning is a deep learning approach in which knowledge from a large pretrained model is reused for a new, typically smaller task. Instead of training a model from scratch, layers learned on a large dataset (such as ImageNet with over a million images) are repurposed as feature extractors. This dramatically reduces training time and improves accuracy, especially when the target dataset is small or less complex, such as MNIST. Transfer learning leverages previously learned low-level and high-level visual features, allowing the model to generalize well even with limited training data.\n",
    "\n",
    "#### Pretrained Models: ResNet and VGG-16\n",
    "\n",
    "ResNet and VGG-16 are two widely used convolutional neural network architectures trained on ImageNet.\n",
    "\n",
    "* **ResNet** introduces residual connections that allow gradients to flow more easily through deep networks, solving the vanishing gradient problem. Its skip connections enable very deep architectures while maintaining stability and performance.\n",
    "* **VGG-16** uses a simple and uniform architecture composed of stacked 3×3 convolutions. Despite its depth, VGG-16 is easy to understand and serves as a strong feature extractor due to its large capacity.\n",
    "\n",
    "In transfer learning, the convolutional layers of these pretrained models are used as fixed feature extractors. Only the final fully connected classifier is replaced and retrained to match the number of target classes (10 for MNIST).\n",
    "\n",
    "#### Feature Extraction and Fine-Tuning\n",
    "\n",
    "Transfer learning typically begins with **feature extraction**, where pretrained convolutional layers are frozen, and only the new classifier layer is trained. This allows the model to make use of powerful learned filters without altering them. If higher performance is needed, **fine-tuning** can be applied by unfreezing some deeper layers, allowing the model to adapt the pretrained features more specifically to the MNIST digit images. Fine-tuning requires a lower learning rate to avoid overwriting useful pretrained knowledge.\n",
    "\n",
    "#### Advantages for MNIST\n",
    "\n",
    "Since MNIST images are simple, small, and grayscale, training a deep CNN from scratch may be unnecessary. Transfer learning with models like ResNet and VGG-16 provides several benefits:\n",
    "\n",
    "* Faster convergence due to rich initial representations\n",
    "* Higher accuracy thanks to pretrained visual features\n",
    "* Reduced need for large amounts of data\n",
    "* Improved generalization on the test set\n",
    "\n",
    "By resizing MNIST digits and converting them to 3-channel images, pretrained architectures can effectively classify digits with very high accuracy, making transfer learning an efficient and powerful method for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13c5387",
   "metadata": {},
   "source": [
    "### **Source Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2458234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12263428",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=3),  # convert 1→3 channels\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8037cb46",
   "metadata": {},
   "source": [
    "#### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aee46a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root=\"./data\", train=True, download=True,\n",
    "                               transform=train_transform)\n",
    "test_dataset  = datasets.MNIST(root=\"./data\", train=False, download=True,\n",
    "                               transform=test_transform)\n",
    "\n",
    "train_subset, val_subset = random_split(train_dataset, [55000, 5000])\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
    "val_loader   = DataLoader(val_subset, batch_size=64)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bcb73b",
   "metadata": {},
   "source": [
    "#### Loading pretrained ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e572112",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "resnet.fc = nn.Linear(resnet.fc.in_features, 10)\n",
    "\n",
    "resnet = resnet.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd238ef",
   "metadata": {},
   "source": [
    "#### Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59b8c8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet.fc.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c9b55e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss, correct = 0, 0\n",
    "\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        correct += (out.argmax(1) == y).sum().item()\n",
    "\n",
    "    return total_loss / len(loader), correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            correct += (out.argmax(1) == y).sum().item()\n",
    "\n",
    "    return total_loss / len(loader), correct / len(loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85a7b242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Acc: 0.8636 | Val Acc: 0.9250\n",
      "Epoch 2/10 | Train Acc: 0.9235 | Val Acc: 0.9354\n",
      "Epoch 3/10 | Train Acc: 0.9318 | Val Acc: 0.9372\n",
      "Epoch 4/10 | Train Acc: 0.9379 | Val Acc: 0.9422\n",
      "Epoch 5/10 | Train Acc: 0.9391 | Val Acc: 0.9466\n",
      "Epoch 6/10 | Train Acc: 0.9453 | Val Acc: 0.9466\n",
      "Epoch 7/10 | Train Acc: 0.9432 | Val Acc: 0.9508\n",
      "Epoch 8/10 | Train Acc: 0.9470 | Val Acc: 0.9478\n",
      "Epoch 9/10 | Train Acc: 0.9478 | Val Acc: 0.9492\n",
      "Epoch 10/10 | Train Acc: 0.9470 | Val Acc: 0.9528\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train(resnet, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc     = evaluate(resnet, val_loader, criterion, device)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e7b7d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet18 Test Accuracy: 0.9414\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(resnet, test_loader, criterion, device)\n",
    "print(\"ResNet18 Test Accuracy:\", test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
