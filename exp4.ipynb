{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e92d9fc5",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 30px; font-weight: bold; margin-bottom: 20px;\">\n",
    "    Program 4\n",
    "</div>\n",
    "\n",
    "\n",
    "### **Aim**\n",
    "Understanding Artificial Neural Networks (ANN) and the role of activation functions in influencing accuracy and data transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484da74f",
   "metadata": {},
   "source": [
    "### **Theory**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dd704e",
   "metadata": {},
   "source": [
    "#### Convolutional Neural Networks (CNNs)\n",
    "\n",
    "Convolutional Neural Networks are specialized deep learning models designed for processing grid-like data, such as images. Unlike fully connected networks, CNNs use convolutional layers that learn spatial features through trainable filters. These filters detect patterns like edges, textures, and shapes by sliding over the input image. The hierarchical nature of CNNs allows shallow layers to learn low-level features and deeper layers to learn high-level representations.\n",
    "\n",
    "A typical CNN architecture includes convolutional layers, activation functions (commonly ReLU), pooling layers for spatial downsampling, and fully connected layers for final classification. CNNs excel in image recognition tasks due to their ability to exploit spatial locality and reduce the number of trainable parameters compared to dense networks.\n",
    "\n",
    "#### Data Augmentation\n",
    "\n",
    "Data augmentation increases dataset variability by applying controlled random transformations such as random cropping, horizontal flipping, rotation, color jitter, and normalization. This technique reduces overfitting and improves model robustness by enabling the CNN to learn invariant features under slight visual distortions. Augmentation acts as a form of regularization, making the model more generalizable to unseen images.\n",
    "\n",
    "#### Optimizers\n",
    "\n",
    "Optimizers determine how the networkâ€™s parameters are updated during training.\n",
    "\n",
    "* **Adam** uses adaptive learning rates and momentum to converge quickly and stably, making it widely used in CNN training.\n",
    "* **SGD with momentum** can yield strong generalization but often requires careful tuning.\n",
    "  Learning rate schedulers such as StepLR adjust the learning rate over epochs, helping avoid plateaus and improving convergence.\n",
    "\n",
    "#### Dropout\n",
    "\n",
    "Dropout is a regularization technique applied primarily in fully connected layers. During training, a percentage of neurons are randomly disabled, preventing the model from relying too heavily on specific activations. This encourages redundancy in feature learning, reduces overfitting, and improves generalization. Dropout is especially useful in deep CNNs where dense layers can easily overfit due to their large number of parameters.\n",
    "\n",
    "#### Importance of These Techniques\n",
    "\n",
    "Combining CNN architectures with data augmentation, dropout, and well-selected optimizers creates a robust and high-performing image classification system. Augmentation increases effective data size, dropout reduces overfitting, and optimizers ensure stable, efficient learning. Together, they significantly enhance accuracy and generalization across real-world image tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456ed457",
   "metadata": {},
   "source": [
    "### **Source Code**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aa2b3c",
   "metadata": {},
   "source": [
    "#### Dependency Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fae947ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2248c3b6",
   "metadata": {},
   "source": [
    "#### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b1e2e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                         (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                         (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590156e1",
   "metadata": {},
   "source": [
    "#### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc7eea0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.CIFAR10(\"./data\", train=True, download=True,\n",
    "                                 transform=train_transform)\n",
    "test_dataset = datasets.CIFAR10(\"./data\", train=False, download=True,\n",
    "                                transform=test_transform)\n",
    "\n",
    "train_subset, val_subset = random_split(train_dataset,\n",
    "                                        [45000, 5000])\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
    "val_loader   = DataLoader(val_subset, batch_size=64)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055ceef9",
   "metadata": {},
   "source": [
    "#### CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58e369b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, dropout=0.3):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 8 * 8, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.features(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdacf72d",
   "metadata": {},
   "source": [
    "### Optimizers and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "497cd4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = CNN(dropout=0.3).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer,\n",
    "                                      step_size=10,\n",
    "                                      gamma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42d268b",
   "metadata": {},
   "source": [
    "#### Training and Evalution loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddf07d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss, total_correct = 0, 0\n",
    "\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_correct += (outputs.argmax(1) == y).sum().item()\n",
    "\n",
    "    return total_loss / len(loader), total_correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, total_correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_correct += (outputs.argmax(1) == y).sum().item()\n",
    "\n",
    "    return total_loss / len(loader), total_correct / len(loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3f9b7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Train Acc: 0.3568 | Val Acc: 0.4764\n",
      "Epoch 2/20 | Train Acc: 0.4925 | Val Acc: 0.5310\n",
      "Epoch 3/20 | Train Acc: 0.5600 | Val Acc: 0.6036\n",
      "Epoch 4/20 | Train Acc: 0.6012 | Val Acc: 0.6274\n",
      "Epoch 5/20 | Train Acc: 0.6308 | Val Acc: 0.6602\n",
      "Epoch 6/20 | Train Acc: 0.6508 | Val Acc: 0.6938\n",
      "Epoch 7/20 | Train Acc: 0.6710 | Val Acc: 0.7128\n",
      "Epoch 8/20 | Train Acc: 0.6782 | Val Acc: 0.7116\n",
      "Epoch 9/20 | Train Acc: 0.6858 | Val Acc: 0.7176\n",
      "Epoch 10/20 | Train Acc: 0.6984 | Val Acc: 0.7116\n",
      "Epoch 11/20 | Train Acc: 0.7158 | Val Acc: 0.7474\n",
      "Epoch 12/20 | Train Acc: 0.7248 | Val Acc: 0.7474\n",
      "Epoch 13/20 | Train Acc: 0.7250 | Val Acc: 0.7480\n",
      "Epoch 14/20 | Train Acc: 0.7284 | Val Acc: 0.7430\n",
      "Epoch 15/20 | Train Acc: 0.7306 | Val Acc: 0.7402\n",
      "Epoch 16/20 | Train Acc: 0.7327 | Val Acc: 0.7538\n",
      "Epoch 17/20 | Train Acc: 0.7379 | Val Acc: 0.7654\n",
      "Epoch 18/20 | Train Acc: 0.7413 | Val Acc: 0.7716\n",
      "Epoch 19/20 | Train Acc: 0.7452 | Val Acc: 0.7642\n",
      "Epoch 20/20 | Train Acc: 0.7484 | Val Acc: 0.7682\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train(model, train_loader,\n",
    "                                  criterion, optimizer, device)\n",
    "    val_loss, val_acc = evaluate(model, val_loader,\n",
    "                                 criterion, device)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | \"\n",
    "          f\"Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0a7fcab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy: 0.7919\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model, test_loader,\n",
    "                               criterion, device)\n",
    "\n",
    "print(\"Final Test Accuracy:\", test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
